import streamlit as st
import os
from PIL import Image
import pandas as pd
import torch
from NeuralModels.FactoryModels import *
from NeuralModels.Vocabulary import Vocabulary
from VARIABLE import IMAGES_SUBDIRECTORY_NAME
from NeuralModels.Attention.SoftAttention import SoftAttention
from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction

# ==================== SIDEBAR OPTIONS ====================
st.sidebar.header("‚öôÔ∏è Tu·ª≥ ch·ªçn")
model_key = st.sidebar.selectbox("Ch·ªçn m√¥ h√¨nh:", list({
    "CaRNetvI", "CaRNetvH", "CaRNetvHC", "CaRNetvHCAttention"
}))
mode = st.sidebar.radio("Ch·∫ø ƒë·ªô ƒë√°nh gi√°:", ["·∫¢nh ƒë∆°n", "To√†n b·ªô th∆∞ m·ª•c"])
theme_mode = st.sidebar.radio("üé® Giao di·ªán", ["Light", "Dark"])

# ==================== THEME MODE ====================
if theme_mode == "Dark":
    st.markdown("""<style>
        body, .stApp { background-color: #0e1117; color: #cfd6e1; }
        h1, h2, h3, .css-1v0mbdj, .css-1d391kg { color: #4fc3f7; }
    </style>""", unsafe_allow_html=True)
else:
    st.markdown("""<style>
        body, .stApp { background-color: #ffffff; color: #000000; }
        h1, h2, h3 { color: #0056b3; }
    </style>""", unsafe_allow_html=True)

# ==================== TITLE & LOGO ====================
logo = Image.open("Uneti-2.png")
st.image(logo, width=90)
st.markdown("""
    <div style='background-color: #e3f2fd; padding: 20px; border-radius: 10px;'>
        <h1 style='padding-top: 10px; color: #0056b3;'>UNETI VCaption üì∑</h1>
        <p style='font-size:18px; color: #333;'>H·ªá th·ªëng sinh ch√∫ th√≠ch ·∫£nh ti·∫øng Vi·ªát s·ª≠ d·ª•ng m√¥ h√¨nh CaRNet</p>
    </div>
""", unsafe_allow_html=True)


# ==================== MODEL CONFIG ====================
MODEL_CONFIGS = {
    "CaRNetvI": {"decoder": Decoder.RNetvI, "attention": None, "attention_dim": 0, "encoder_dim": 2086, "hidden_dim": 1024},
    "CaRNetvH": {"decoder": Decoder.RNetvH, "attention": None, "attention_dim": 0, "encoder_dim": 1024, "hidden_dim": 1024},
    "CaRNetvHC": {"decoder": Decoder.RNetvHC, "attention": None, "attention_dim": 0, "encoder_dim": 1024, "hidden_dim": 1024},
    "CaRNetvHCAttention": {"decoder": Decoder.RNetvHCAttention, "attention": "SoftAttention", "attention_dim": 1024, "encoder_dim": 2048, "hidden_dim": 1024}
}

@st.cache(allow_output_mutation=True)
def load_model(model_key):
    cfg = MODEL_CONFIGS[model_key]
    encoder = FactoryEncoder(Encoder.CResNet50Attention if cfg["attention"] else Encoder.CResNet50)
    decoder = FactoryDecoder(cfg["decoder"])
    attention = SoftAttention if cfg["attention"] == "SoftAttention" else None
    vocab = Vocabulary()
    net = FactoryNeuralNet(NeuralNet.CaRNet)(
        encoder=encoder,
        decoder=decoder,
        attention=attention,
        attention_dim=cfg["attention_dim"],
        net_name=model_key,
        encoder_dim=cfg["encoder_dim"],
        hidden_dim=cfg["hidden_dim"],
        padding_index=vocab.predefined_token_idx()["<PAD>"],
        vocab_size=len(vocab.word2id.keys()),
        embedding_dim=vocab.embeddings.shape[1],
        device="cpu"
    )
    net.load("./.saved")
    return net, vocab

# ==================== BLEU ====================
def compute_bleu(reference, candidate):
    smoothie = SmoothingFunction().method4
    return sentence_bleu([reference.split()], candidate.split(), smoothing_function=smoothie)

net, vocab = load_model(model_key)
st.markdown("---")

# ==================== MAIN UI ====================
if mode == "·∫¢nh ƒë∆°n":
    st.subheader("üì• T·∫£i ·∫£nh l√™n ƒë·ªÉ sinh caption")
    uploaded_file = st.file_uploader("Ch·ªçn ·∫£nh", type=["jpg", "jpeg", "png"])
    if uploaded_file:
        image = Image.open(uploaded_file).convert("RGB")
        st.image(image, caption="·∫¢nh ƒë√£ ch·ªçn", use_column_width=True)
        if st.button("üìå Sinh caption"):
            with st.spinner("‚è≥ ƒêang x·ª≠ l√Ω..."):
                tokens = net.eval_image_caption(image, vocab)
                caption = " ".join([w for w in tokens if w not in ("<START>", "<END>")])

                st.markdown("""
                <div style='background-color: #e8f5e9; padding: 20px; border-radius: 8px; margin-top: 20px;'>
                    <h4 style='color: green; margin-bottom: 10px;'>‚úÖ Caption:</h4>
                    <p style='font-size: 20px; font-weight: bold; color: #1b5e20;'>""" + caption + """</p>
                </div>
                """, unsafe_allow_html=True)

elif mode == "To√†n b·ªô th∆∞ m·ª•c":
    st.subheader("üìÇ ƒê√°nh gi√° nhi·ªÅu ·∫£nh trong th∆∞ m·ª•c")
    dataset_folder = st.text_input("üìÅ Nh·∫≠p ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c ch·ª©a ·∫£nh", "./dataset")

    if st.button("üöÄ B·∫Øt ƒë·∫ßu ƒë√°nh gi√°"):
        image_dir = os.path.join(dataset_folder, IMAGES_SUBDIRECTORY_NAME)
        if not os.path.exists(image_dir):
            st.error("‚ùå Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c ·∫£nh.")
        else:
            image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('jpg', 'jpeg', 'png'))]
            results = []

            for file in image_files:
                try:
                    img = Image.open(os.path.join(image_dir, file)).convert("RGB")
                    tokens = net.eval_image_caption(img, vocab)
                    caption = " ".join([w for w in tokens if w not in ("<START>", "<END>")])
                    results.append({"image_name": file, "caption": caption})
                except Exception as e:
                    results.append({"image_name": file, "caption": f"ERROR: {e}"})

            df = pd.DataFrame(results)
            st.success("üéâ ƒê√£ x·ª≠ l√Ω xong to√†n b·ªô ·∫£nh!")
            st.dataframe(df)
            df.to_csv("eval_results.csv", sep="|", index=False)
            st.info("üì• K·∫øt qu·∫£ ƒë√£ l∆∞u t·∫°i file eval_results.csv")
