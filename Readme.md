
Ôªø# Th·ª±c hi·ªán sinh ch√∫ gi·∫£i ·∫£nh b·∫±ng m√¥ h√¨nh EN-DE, C[aA]RNet!   
[![forthebadge made-with-python](http://ForTheBadge.com/images/badges/made-with-python.svg)](https://www.python.org/)   ![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white)  [![PyPI license](https://img.shields.io/pypi/l/ansicolortags.svg)](https://pypi.python.org/pypi/ansicolortags/)  

**Convolutional(and|Attention)RecurrentNet!**
M·ª•c ti√™u c·ªßa d·ª± √°n l√† x√¢y d·ª±ng m·ªôt m√¥ h√¨nh Neural ƒë·ªÉ sinh ch√∫ gi·∫£i cho ·∫£nh.

V·ªõi m·ªôt b·ªô d·ªØ li·ªáu, m·ªôt m·∫°ng th·∫ßn kinh g·ªìm:
- B·ªô m√£ h√≥a (Encoder - M·∫°ng Neural Residual ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán tr∆∞·ªõc)
- B·ªô gi·∫£i m√£ (Decoder - M√¥ h√¨nh LSTM)
S·∫Ω bi·ªÉu di·ªÖn ·∫£nh trong m·ªôt kh√¥ng gian do b·ªô m√£ h√≥a x√°c ƒë·ªãnh, bi·ªÉu di·ªÖn n√†y ƒë∆∞·ª£c ƒë∆∞a v√†o b·ªô gi·∫£i m√£ (theo nhi·ªÅu c√°ch kh√°c nhau) ƒë·ªÉ h·ªçc sinh ra ch√∫ th√≠ch,
li√™n k·∫øt v·ªõi ·∫£nh v√† c√°c t·ª´ ƒë√£ sinh ra ·ªü m·ªói b∆∞·ªõc th·ªùi gian b·ªüi LSTM.

B·∫°n c√≥ th·ªÉ xem b·∫£ng m·ª•c l·ª•c d∆∞·ªõi ƒë√¢y:


Trong th∆∞ m·ª•c ·∫©n `.saved` c√≥ th·ªÉ t√¨m th·∫•y t·∫•t c·∫£ c√°c phi√™n b·∫£n ƒë√£ hu·∫•n luy·ªán c·ªßa C[aA]RNet.

# M·ª•c l·ª•c
- [M·ªôt hi·ªán th·ª±c Pythonic cho B√†i to√°n Ch√∫ th√≠ch ·∫¢nh, C[aA]RNet!](#thuc-hien-sinh-chu-giai-anh-bang-mo-hinh-en-de-caarnet)
- [M·ª•c l·ª•c](#muc-luc)
- [Ki·∫øn th·ª©c ti·ªÅn ƒë·ªÅ](#kien-thuc-tien-de)
- [C√°ch ch·∫°y m√£ ngu·ªìn](#cach-chay-ma-nguon)
  * [C√°c phi√™n b·∫£n Python h·ªó tr·ª£](#cac-phien-ban-python-ho-tro)
  * [Th∆∞ vi·ªán ph·ª• thu·ªôc](#thu-vien-phu-thuoc)
  * [Bi·∫øn m√¥i tr∆∞·ªùng](#bien-moi-truong)
  * [Gi·∫£i th√≠ch CLI](#giai-thich-cli)
    * [V√≠ d·ª•](#vi-du)
  * [T√≠ch h·ª£p GPU](#tich-hop-gpu)
- [Pipeline D·ªØ li·ªáu](#pipeline-du-lieu)
  * [ƒê·ªãnh d·∫°ng Dataset](#dinh-dang-dataset)
    + [·∫¢nh](#anh)
    + [K·∫øt qu·∫£](#ket-qua)
- [Script sinh ra nh·ªØng g√¨](#script-sinh-ra-nhung-gi)
  * [Trong qu√° tr√¨nh hu·∫•n luy·ªán](#trong-qua-trinh-huan-luyen)
  * [Trong qu√° tr√¨nh ƒë√°nh gi√°](#trong-qua-trinh-danh-gia)
- [C·∫•u tr√∫c d·ª± √°n](#cau-truc-du-an)
  * [Filesystem](#filesystem)
  * [Interfaces](#interfaces)
  * [Encoder](#encoder)
    + [CResNet50](#cresnet50)
    + [CResNet50Attention](#cresnet50attention)
  * [Decoder](#decoder)
    + [RNetvI](#rnetvi)
    + [RNetvH](#rnetvh)
    + [RNetvHC](#rnetvhc)
    + [RNetvHCAttention](#rnetvhcattention)
- [Quy tr√¨nh hu·∫•n luy·ªán](#quy-trinh-huan-luyen)
  * [Lo·∫°i h√†m m·∫•t m√°t](#loai-ham-mat-mat)
    + [L∆∞u √Ω: M·∫•t m√°t trong phi√™n b·∫£n attention](#luu-y-mat-mat-trong-phien-ban-attention)
- [Th√≠ nghi·ªám c√° nh√¢n](#thi-nghiem-ca-nhan)
- [T√†i li·ªáu tham kh·∫£o](#tai-lieu-tham-khao)
  * [T√°c gi·∫£](#tac-gia)

# Ki·∫øn th·ª©c ti·ªÅn ƒë·ªÅ
ƒê·ªÉ hi·ªÉu r√µ h∆°n v·ªÅ m√£ ngu·ªìn v√† th√¥ng tin b√™n trong, v√¨ repo n√†y h∆∞·ªõng t·ªõi vi·ªác d·ªÖ hi·ªÉu cho c·∫£ ng∆∞·ªùi m·ªõi t√≤ m√≤ l·∫´n ng∆∞·ªùi ƒë√£ c√≥ chuy√™n m√¥n, b·∫°n n√™n tham kh·∫£o c√°c t√†i li·ªáu sau:

-[T√†i li·ªáu Pytorch](https://pytorch.org/docs/stable/index.html)
-[M·∫°ng Neural T√≠ch ch·∫≠p (Stanford Edu)](https://cs231n.github.io/convolutional-networks/)
-[M·∫°ng Neural H·ªìi ti·∫øp (Stanford Edu)](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks#architecture)
-[M·∫°ng Neural Residual (D2L AI)](https://d2l.ai/chapter_convolutional-modern/resnet.html)


# C√°ch ch·∫°y m√£ ngu·ªìn
[![Linux](https://svgshare.com/i/Zhy.svg)](https://svgshare.com/i/Zhy.svg) [![macOS](https://svgshare.com/i/ZjP.svg)](https://svgshare.com/i/ZjP.svg) [![Windows](https://svgshare.com/i/ZhY.svg)](https://svgshare.com/i/ZhY.svg)

M√£ ngu·ªìn c√≥ th·ªÉ ch·∫°y tr√™n m·ªçi h·ªá ƒëi·ªÅu h√†nh, b·∫°n c√≥ th·ªÉ d√πng b·∫•t k·ª≥ h·ªá ƒëi·ªÅu h√†nh n√†o. Tuy nhi√™n, m·ªôt m√°y c·∫•u h√¨nh cao l√† b·∫Øt bu·ªôc, v√¨ l∆∞·ª£ng d·ªØ li·ªáu l·ªõn c√≥ th·ªÉ g√¢y l·ªói h·∫øt b·ªô nh·ªõ tr√™n m√°y y·∫øu.
**L∆∞u √Ω r·∫±ng b·∫°n c·∫ßn t·∫£i b·ªô d·ªØ li·ªáu tr∆∞·ªõc khi ch·∫°y v√† n√≥ ph·∫£i ƒë√∫ng ƒë·ªãnh d·∫°ng y√™u c·∫ßu**
C√°ch chu·∫©n b·ªã dataset cho hu·∫•n luy·ªán C[aA]RNet?

 1. [T·∫£i v·ªÅ](https://drive.google.com/file/d/1Y9nuHtmO0p0Jd2lvzIF5euiemkJHJ2IU/view?usp=sharing) b·ªô d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c vietsub t·ª´ Kaggle Flickr30k.
 2. Gi·∫£i n√©n v√†o th∆∞ m·ª•c g·ªëc c·ªßa repo.
 3. ƒê·ªïi t√™n th∆∞ m·ª•c th√†nh *dataset*
 4. ƒê·ªïi t√™n th∆∞ m·ª•c ·∫£nh th√†nh *images*

N·∫øu b·∫°n c√≥ tr∆∞·ªùng h·ª£p ƒë·∫∑c bi·ªát, c√≥ th·ªÉ ch·ªânh file [VARIABLE.py](#bien-moi-truong) v√†/ho·∫∑c m·ªôt s·ªë tham s·ªë t√πy ch·ªçn tr∆∞·ªõc khi ch·∫°y script ([Gi·∫£i th√≠ch CLI](#giai-thich-cli)
).

## C√°c phi√™n b·∫£n Python h·ªó tr·ª£
M√£ ngu·ªìn s·∫µn s√†ng ch·∫°y v·ªõi m·ªçi phi√™n b·∫£n python l·ªõn h∆°n 3.6.
Nh∆∞ b·∫°n s·∫Ω th·∫•y trong m√£, m·ªôt s·ªë ti·ªán √≠ch kh√¥ng c√≥ ·ªü python <3.9. C√°c tr∆∞·ªùng h·ª£p n√†y ƒë·ªÅu c√≥ ch√∫ th√≠ch trong m√£, b·∫°n c√≥ th·ªÉ ch·ªçn b·∫≠t/t·∫Øt theo √Ω mu·ªën.

## Th∆∞ vi·ªán ph·ª• thu·ªôc
| Th∆∞ vi·ªán | Phi√™n b·∫£n  |
| ------------ | ------------ |
|  Torch | 1.3.0+cu100  |
|  Torchvision | 0.4.1+cu100  |
|  Pillow | 8.4.0  |
|  Numpy | 1.19.5  |
|  Pandas | 1.1.5  |
|  Matplotlib | 3.3.4  |

Trong th∆∞ m·ª•c g·ªëc c√≥ file requirements.txt, b·∫°n c√≥ th·ªÉ c√†i t·∫•t c·∫£ c√°c package c·∫ßn thi·∫øt v√†o m√¥i tr∆∞·ªùng (ho·∫∑c v.env.) b·∫±ng l·ªánh sau, ch·∫°y trong shell v·ªõi m√¥i tr∆∞·ªùng ƒë√£ k√≠ch ho·∫°t:
=======
Ôªø# VN Captioning
# H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng m√¥ h√¨nh CaRNet
## Link DATASET v√† TESTSET: 
>>>>>>> 39317fbf606aad6a55c26429a30d4b4d1c206329
```bash
https://drive.google.com/file/d/1Y9nuHtmO0p0Jd2lvzIF5euiemkJHJ2IU/view?usp=drive_link
```
## üöÄ Hu·∫•n luy·ªán m√¥ h√¨nh (Training)

### CaRNetvI
```bash
python main.py RNetvI train 0 1024 --dataset_folder ./dataset --device cuda:0 --epochs 150
```

### CaRNetvH
```bash
python main.py RNetvH train 1024 1024 --dataset_folder ./dataset --device cuda:0 --epochs 150
```

### CaRNetvHC
```bash
python main.py RNetvHC train 1024 1024 --dataset_folder ./dataset --device cuda:0 --epochs 150
```

### CaRNetvHCAttention
```bash
python main.py RNetvHCAttention train 1024 1024 --dataset_folder ./dataset --device cuda:0 --epochs 150 --attention t --attention_dim 1024
```

---

## üîç ƒê√°nh gi√° m√¥ h√¨nh (Single Image Evaluation)

### CaRNetvI
```bash
python eval.py RNetvI eval 5078 1024 --image_path ./33465647.jpg
```

### CaRNetvH
```bash
python eval.py RNetvH eval 1024 1024 --image_path ./33465647.jpg
```

### CaRNetvHC
```bash
python eval.py RNetvHC eval 1024 1024 --image_path ./33465647.jpg
```

### CaRNetvHCAttention
```bash
python eval.py RNetvHCAttention eval 1024 1024 --attention t --attention_dim 1024 --image_path ./33465647.jpg
```

---

## üìÅ ƒê√°nh gi√° to√†n b·ªô th∆∞ m·ª•c ·∫£nh (Folder Evaluation)

```bash
python eval.py RNetvHCAttention eval 1024 1024 --attention t --attention_dim 1024 --dataset_folder ./testset --output_csv ./testset/caption_test4.csv
```

> üìÑ File `results.csv` s·∫Ω ƒë∆∞·ª£c t·∫°o trong ƒë∆∞·ªùng d·∫´n `--output_csv`, theo ƒë·ªãnh d·∫°ng: `image_name| comment_number| comment`.

---

## üìä ƒê√°nh gi√° ƒë·ªô ch√≠nh x√°c BLEU

```bash
python bleu_newest.py ./caption_test.csv ./results.csv
```

> So s√°nh gi·ªØa nh√£n th·ª±c t·∫ø (`caption_test.csv`) v√† d·ª± ƒëo√°n t·ª´ m√¥ h√¨nh (`results.csv`).

---

üìÅ **Ch√∫ √Ω c·∫•u tr√∫c th∆∞ m·ª•c:**
- `./dataset/` ho·∫∑c `./testset/`
  - `images/` (th∆∞ m·ª•c ch·ª©a ·∫£nh)
  - `results.csv` (file ch√∫ th√≠ch, ph√¢n t√°ch b·∫±ng d·∫•u `|`)

---

<<<<<<< HEAD
## T√≠ch h·ª£p GPU

Nh∆∞ b·∫°n ƒë√£ th·∫•y ·ªü ph·∫ßn CLI, m√£ ngu·ªìn h·ªó tr·ª£ GPU (ch·ªâ NVIDIA hi·ªán t·∫°i).
B·∫°n c·∫ßn c√†i driver CUDA, ƒë·ªÉ ƒë·ªìng b·ªô v·ªõi torch trong requirements.txt v√† driver, b·∫°n n√™n c√†i NVIDIA driver v440 + Cuda 10.2.

# Pipeline D·ªØ li·ªáu

ƒê·ªÉ hi·ªÉu r√µ h∆°n v·ªÅ nh·ªØng g√¨ x·∫£y ra trong script, h√£y h√¨nh dung pipeline d·ªØ li·ªáu nh∆∞ sau:

- Dataset: ch·ª©a t·∫•t c·∫£ c√°c v√≠ d·ª• (ch∆∞a t√°ch train/test/val)
- Vocabulary: m·ªói v√≠ d·ª• c√≥ caption, n√™n c·∫ßn m·ªôt t·ª´ ƒëi·ªÉn ch·ª©a t·∫•t c·∫£ c√°c t·ª´.
- C[aA]RNet: m·∫°ng neural, ch∆∞a ph√¢n bi·ªát c√≥/kh√¥ng Attention. 

Gi·∫£i th√≠ch chi ti·∫øt v·ªÅ t·ª´ng th√†nh ph·∫ßn ·ªü c√°c ph·∫ßn sau.
Hi·ªán t·∫°i ch·ªâ c·∫ßn bi·∫øt script c·∫ßn 3 th√†nh ph·∫ßn n√†y ƒë·ªÉ l√†m vi·ªác v·ªõi d·ªØ li·ªáu.
![Data Pipeline](https://i.imgur.com/d8OtmUu.png)
H√£y t∆∞·ªüng t∆∞·ª£ng m·ªói thao t√°c l√† m·ªôt b∆∞·ªõc th·ªùi gian.
- T_0: Load dataset
- T_1:
  - a) Dataset ƒë∆∞·ª£c chuy·ªÉn th√†nh Dataloader (l·ªõp c·ªßa pytorch).
  - b) T·∫°o t·ª´ ƒëi·ªÉn t·ª´ dataset.
 - T_2: T·∫°o dataloader
 - T_3: C[aA]RNet d√πng c·∫£ dataloader v√† vocabulary ƒë·ªÉ hu·∫•n luy·ªán, khi ƒë√°nh gi√° ch·ªâ d√πng vocabulary v√¨ dataloader size 1.
 
## ƒê·ªãnh d·∫°ng Dataset

C√°ch ƒë·ªãnh nghƒ©a Dataset theo c·∫•u tr√∫c c·ªßa b·ªô Flickr30k Image Dataset: https://www.kaggle.com/hsankesara/flickr-image-dataset

C·∫•u tr√∫c filesystem nh∆∞ sau:

dataset/
‚îú‚îÄ images/
‚îÇ  ‚îú‚îÄ pippo_pluto_paperino.jpg
‚îú‚îÄ results.csv

 ### ·∫¢nh
Th∆∞ m·ª•c images ch·ª©a c√°c ·∫£nh jpeg, t√™n kh√¥ng c√≥ d·∫•u c√°ch.
`pippo_pluto_paperino.jpg`

### K·∫øt qu·∫£
File ch·ª©a c√°c caption.
**V√¨** caption c√≥ th·ªÉ ch·ª©a d·∫•u ph·∫©y *(,)* , n√™n k√Ω t·ª± ph√¢n t√°ch l√† d·∫•u g·∫°ch ƒë·ª©ng *(|)*.
D√≤ng ƒë·∫ßu l√† header, c√°c c·ªôt nh∆∞ sau:
| Tham s·ªë | Ki·ªÉu     | M√¥ t·∫£                       |
| :-------- | :------- | :-------------------------------- |
| `image_name`      | `string` | T√™n file ·∫£nh t∆∞∆°ng ·ª©ng |
| `comment_number`      | `int` | Ch·ªâ s·ªë c·ªßa caption |
| `comment`*      | `string` | Caption |

*Caption n√™n t√°ch t·ª´ b·∫±ng d·∫•u c√°ch.
D·∫•u ch·∫•m (".") ƒë√°nh d·∫•u k·∫øt th√∫c caption.

# Script sinh ra nh·ªØng g√¨
V√¨ d·ª± √°n c√≤n ph√°t tri·ªÉn ti·∫øp, n√™n c·∫ßn m√¥ t·∫£ c√°c output ch√≠nh:

- Output trong qu√° tr√¨nh hu·∫•n luy·ªán.
- Output khi ƒë√°nh gi√°.

## Trong qu√° tr√¨nh hu·∫•n luy·ªán
Sinh ra c√°c output sau:

 1. M·ªói mini-batch c·ªßa m·ªói epoch: l∆∞u loss v√† accuracy v√†o Dataframe.
 2. M·ªói epoch, l∆∞u accuracy tr√™n t·∫≠p validation v√†o Dataframe.
 3. M·ªói epoch, l∆∞u m·ªôt caption sinh ra t·ª´ ·∫£nh cu·ªëi c√πng c·ªßa batch cu·ªëi c√πng trong validation.
 4. M·ªói khi ƒë·∫°t accuracy t·ªët nh·∫•t tr√™n validation, l∆∞u model v√†o b·ªô nh·ªõ.

### 1
Dataframe l∆∞u th√†nh file *train_results.csv* cu·ªëi m·ªói epoch, c·∫•u tr√∫c:
| Tham s·ªë | Ki·ªÉu     | M√¥ t·∫£                       |
| :-------- | :------- | :-------------------------------- |
|   Epoch   | `int` | ID c·ªßa epoch |
|   Batch   | `int` | ID c·ªßa batch |
|   Loss    | `float` | Loss c·ªßa batch|
|   Accuracy    | `float` | Accuracy c·ªßa batch |

### 2
Dataframe l∆∞u th√†nh file *validation_results.csv* cu·ªëi m·ªói epoch, c·∫•u tr√∫c:
| Tham s·ªë | Ki·ªÉu     | M√¥ t·∫£                       |
| :-------- | :------- | :-------------------------------- |
|   Epoch   | `int` | ID c·ªßa epoch |
|   Accuracy    | `float` | Accuracy tr√™n validation|

### 3
Tr√≠ch ƒë·∫∑c tr∆∞ng t·ª´ ·∫£nh cu·ªëi c·ªßa batch cu·ªëi validation, ƒë∆∞a v√†o net ·ªü ch·∫ø ƒë·ªô eval.
Sinh file caption.png g·ªìm caption sinh ra v√† ·∫£nh g·ªëc.
N·∫øu c√≥ attention, sinh th√™m attention.png th·ªÉ hi·ªán attention cho t·ª´ng t·ª´.

### 4
M·ªói khi ƒë·∫°t accuracy t·ªët nh·∫•t tr√™n validation, l∆∞u model v√†o b·ªô nh·ªõ.
Th∆∞ m·ª•c l∆∞u l√† `.saved` ·ªü g·ªëc repo.
Pattern file:

 - Encoder: NetName_encoderdim_hiddendim_attentiondim_C,pth
 - Decoder: NetName_encoderdim_hiddendim_attentiondim_R,pth
 
C√°c tham s·ªë n√†y ph·ª• thu·ªôc v√†o c·∫•u h√¨nh khi hu·∫•n luy·ªán.

## Trong qu√° tr√¨nh ƒë√°nh gi√°
·∫¢nh ƒë∆∞·ª£c load, ti·ªÅn x·ª≠ l√Ω, ƒë∆∞a v√†o C[aA]RNet.
Sinh file caption.png g·ªìm caption sinh ra v√† ·∫£nh g·ªëc.
N·∫øu c√≥ attention, sinh th√™m attention.png th·ªÉ hi·ªán attention cho t·ª´ng t·ª´.

# C·∫•u tr√∫c d·ª± √°n
C·∫•u tr√∫c d·ª± √°n t√≠nh ƒë·∫øn kh·∫£ nƒÉng m·ªü r·ªông t·ª´ c·ªông ƒë·ªìng ho·∫∑c c√° nh√¢n.
S∆° ƒë·ªì d∆∞·ªõi ƒë√¢y ch·ªâ mang t√≠nh t·ªïng qu√°t, th·ªÉ hi·ªán c√°c th·ª±c th·ªÉ v√† quan h·ªá ph·ª• thu·ªôc.
M·ªói ph∆∞∆°ng th·ª©c ƒë·ªÅu c√≥ docstring, h√£y d√πng l√†m t√†i li·ªáu tham kh·∫£o.
![UML](https://i.imgur.com/xmGekz5.jpg)

## Filesystem
C·∫•u tr√∫c filesystem nh∆∞ sau:

    C[aA]RNet/
    ‚îú‚îÄ .saved/
    ‚îú‚îÄ dataset/
    ‚îÇ  ‚îú‚îÄ images/
    ‚îÇ  ‚îú‚îÄ results.csv
    ‚îú‚îÄ NeuralModels/
    ‚îÇ  ‚îú‚îÄ Attention/
    ‚îÇ  ‚îÇ  ‚îú‚îÄ IAttention.py
    ‚îÇ  ‚îÇ  ‚îú‚îÄ SoftAttention.py
    ‚îÇ  ‚îú‚îÄ Decoder/
    ‚îÇ  ‚îÇ  ‚îú‚îÄ IDecoder.py
    ‚îÇ  ‚îÇ  ‚îú‚îÄ RNetvH.py
    ‚îÇ  ‚îÇ  ‚îú‚îÄ RNetvHC.py
    ‚îÇ  ‚îÇ  ‚îú‚îÄ RNetvHCAttention.py
    ‚îÇ  ‚îÇ  ‚îú‚îÄ RNetvI.py
    ‚îÇ  ‚îú‚îÄ Encoder/
    ‚îÇ  ‚îÇ  ‚îú‚îÄ IEncoder.py
    ‚îÇ  ‚îÇ  ‚îú‚îÄ CResNet50.py
    ‚îÇ  ‚îÇ  ‚îú‚îÄ CResNet50Attention.py
    ‚îÇ  ‚îú‚îÄ CaARNet.py
    ‚îÇ  ‚îú‚îÄ Dataset.py
    ‚îÇ  ‚îú‚îÄ FactoryModels.py
    ‚îÇ  ‚îú‚îÄ Metrics.py
    ‚îÇ  ‚îú‚îÄ Vocabulary.py
    ‚îú‚îÄ VARIABLE.py
    ‚îú‚îÄ main.py
 
| File | M√¥ t·∫£ |
|--|--|
| `VARIABLE.py` | Gi√° tr·ªã h·∫±ng d√πng trong d·ª± √°n|
| `main.py` | ƒêi·ªÉm v√†o ƒë·ªÉ ch·∫°y net|
| `IAttention.py` | Interface cho attention m·ªõi |
| `SoftAttention.py` | Hi·ªán th·ª±c Soft Attention |
| `IDecoder.py` | Interface cho decoder m·ªõi |
| `RNetvH.py` | Hi·ªán th·ª±c decoder LSTM H-version |
| `RNetvHC.py` | Hi·ªán th·ª±c decoder LSTM HC-version |
| `RNetvHCAttention.py` | Hi·ªán th·ª±c decoder LSTM HC-version v·ªõi Attention|
| `IEncoder.py` | Interface cho encoder m·ªõi |
| `CResNet50.py` | ResNet50 l√†m encoder |
| `CResNet50Attention.py` | ResNet50 cho attention |
| `CaRNet.py` | Hi·ªán th·ª±c C[aA]RNet |
| `Dataset.py` |  Qu·∫£n l√Ω dataset |
| `FactoryModels.py` | Factory Pattern cho c√°c m√¥ h√¨nh |
| `Metrics.py` | Sinh file b√°o c√°o |
| `Vocabulary.py` | Qu·∫£n l√Ω t·ª´ ƒëi·ªÉn |


## Interfaces
Interface d√πng ƒë·ªÉ ƒë·ªãnh nghƒ©a h·ª£p ƒë·ªìng cho ai mu·ªën hi·ªán th·ª±c Encoder, Decoder ho·∫∑c Attention m·ªõi.
Tu√¢n th·ªß interface l√† b·∫Øt bu·ªôc, docstring c√≥ g·ª£i √Ω tham s·ªë cho t·ª´ng ph∆∞∆°ng th·ª©c.

## Encoder
Hai encoder d·ª±a tr√™n ResNet50 *(He et al. 2015, Deep Residual Learning for Image Recognition)*.
T√πy c√≥ d√πng attention hay kh√¥ng, s·∫Ω b·ªè m·ªôt ho·∫∑c nhi·ªÅu l·ªõp cu·ªëi c·ªßa net g·ªëc.

![ResNet50](https://www.researchgate.net/publication/336805103/figure/fig4/AS:817882309079050@1572009746601/ResNet-50-neural-network-architecture-56.ppm)

(Ki·∫øn tr√∫c m·∫°ng ResNet-50 [56].) [Privacy-Constrained Biometric System for Non-Cooperative Users](https://www.researchgate.net/publication/336805103_Privacy-Constrained_Biometric_System_for_Non-Cooperative_Users)

### CResNet50
B·∫£n 1 b·ªè l·ªõp cu·ªëi c·ªßa ResNet50, ƒë·ªÉ l·ªô GlobalAveragePooling. Sau pooling l√† m·ªôt l·ªõp tuy·∫øn t√≠nh k√≠ch th∆∞·ªõc *encoder_dim*, nh·∫≠n ƒë·∫ßu v√†o l√† output c·ªßa AveragePooling (ResNet50 l√† 2048).
 
### CResNet50Attention
B·∫£n 2 b·ªè 2 l·ªõp cu·ªëi c·ªßa ResNet50 (AveragePooling + FC), ƒë·ªÉ l·ªô l·ªõp t√≠ch ch·∫≠p cu·ªëi cho tensor d·∫°ng: (Heigth/32, Width/32, 2048). 
M·ªói v√πng l√† m·ªôt vector 2048 chi·ªÅu. 
V·ªõi ·∫£nh RGB vu√¥ng (3,224,224) th√¨ t·ªïng s·ªë v√πng l√† 49.

## Decoder
Decoder d·ª±a tr√™n RNN, c·ª• th·ªÉ l√† LSTM (Long-Short Term Memory), m·ªôt lo·∫°i RNN c·∫≠p nh·∫≠t tr·∫°ng th√°i ·∫©n ƒë·∫∑c bi·ªát.
![LSTM](https://www.researchgate.net/profile/Xuan_Hien_Le2/publication/334268507/figure/fig8/AS:788364231987201@1564972088814/The-structure-of-the-Long-Short-Term-Memory-LSTM-neural-network-Reproduced-from-Yan.png)
*(C·∫•u tr√∫c LSTM. T√°i b·∫£n t·ª´ Yan [38].)* [·ª®ng d·ª•ng LSTM cho d·ª± b√°o l≈©](https://www.researchgate.net/publication/334268507_Application_of_Long_Short-Term_Memory_LSTM_Neural_Network_for_Flood_Forecasting)

M·ªói m√¥ h√¨nh xu·∫•t ph√°t t·ª´ √Ω t∆∞·ªüng n√†y v√† th·ª≠ c√°c c√°ch kh√°c nhau ƒë·ªÉ ƒë∆∞a context ·∫£nh t·ª´ encoder v√†o:

 1. RNetvI: Context ·∫£nh l√† input ƒë·∫ßu ti√™n c·ªßa LSTM t·∫°i t_0.
 2. RNetvH: Context ·∫£nh ƒë∆∞·ª£c ƒë∆∞a v√†o hidden state t·∫°i t_0.
 3. RNetvHC: Context ·∫£nh ƒë∆∞a v√†o c·∫£ hidden v√† cell state t·∫°i t_0.
 4. RNetvHCAttention: Context ·∫£nh ƒë∆∞a v√†o hidden v√† cell state, m·ªói b∆∞·ªõc t n·ªëi th√™m vector attention v√†o input LSTM. 
 
### RNetvI
B·∫£n 1 d√πng context ·∫£nh l√†m input ƒë·∫ßu ti√™n c·ªßa lstm.

![RNetvI](https://i.imgur.com/PAxWnQy.png)
(Vinyals et al. 2014) [Show and Tell: A Neural Image Caption Generator](https://arxiv.org/abs/1411.4555) 

R√†ng bu·ªôc duy nh·∫•t l√† context ·∫£nh ph·∫£i chi·∫øu v√†o kh√¥ng gian embedding t·ª´.

### RNetvH
RNetvH kh·ªüi t·∫°o hidden state t·∫°i t_0 b·∫±ng context ·∫£nh t·ª´ ResNet.

![RNetvH](https://i.imgur.com/9b2vVt3.jpg)
(Vinyals et al. 2014) [Show and Tell: A Neural Image Caption Generator](https://arxiv.org/abs/1411.4555) (B·∫£n ch·ªânh s·ª≠a b·ªüi Thisorp)
### RNetvHC
RNetvHC kh·ªüi t·∫°o c·∫£ hidden v√† cell state t·∫°i t_0 b·∫±ng context ·∫£nh t·ª´ ResNet
![RNetvHC](https://i.imgur.com/pCrj3TS.jpg)
(Vinyals et al. 2014) [Show and Tell: A Neural Image Caption Generator](https://arxiv.org/abs/1411.4555) (B·∫£n ch·ªânh s·ª≠a b·ªüi Thisorp)

### RNetvHCAttention
B·∫£n n√†y k·∫øt h·ª£p RNetvHC v·ªõi Attention.
![RNetvHCAttention](https://i.imgur.com/64rTN7q.png)
Credit to Thisorp et al. 2022

# Quy tr√¨nh hu·∫•n luy·ªán
Quy tr√¨nh hu·∫•n luy·ªán g·ªìm t·∫≠p train v√† t·∫≠p validation.

 - T·∫≠p train ƒë∆∞·ª£c chia th√†nh c√°c mini-batch (tham s·ªë) v√† x√°o tr·ªôn.
	 - V·ªõi m·ªói mini-batch: 
		 - ƒê∆∞a batch v√†o encoder ƒë·ªÉ sinh context vector cho t·ª´ng ph·∫ßn t·ª≠.
		 - Gi·∫£ s·ª≠ tensor caption (ƒë√£ chuy·ªÉn th√†nh vector id t·ª´ vocabulary) c·ªßa batch ·∫£nh ƒë∆∞·ª£c padding b·∫±ng 0 v√† s·∫Øp x·∫øp gi·∫£m d·∫ßn theo ƒë·ªô d√†i.
		 - Context vector v√† caption ƒë∆∞·ª£c ƒë∆∞a v√†o Decoder.
		 - Output decoder l√† input cho pack_padded_sequence, lo·∫°i b·ªè v√πng pad c·ªßa m·ªói caption.
		 - T√≠nh loss, backpropagation v√† c·∫≠p nh·∫≠t tr·ªçng s·ªë.
 - ƒê√°nh gi√° accuracy tr√™n t·∫≠p validation.
	 - N·∫øu c√≥ model t·ªët nh·∫•t m·ªõi, l∆∞u l·∫°i model.

## Lo·∫°i h√†m m·∫•t m√°t
H√†m m·∫•t m√°t d√πng l√† CrossEntropyLoss, v√¨ pytorch n·ªôi b·ªô d√πng soft-max tr√™n m·ªói output t (output lstm c√≥ k√≠ch th∆∞·ªõc b·∫±ng vocab, ta mu·ªën ch·ªçn t·ª´ x√°c su·∫•t cao nh·∫•t) v√† NegativeLogLikelihood.
<p align="center">
  <img src="https://i.imgur.com/PBZbhjR.png" />
</p>
V·ªõi p_t:
<p align="center">
  <img src="https://i.imgur.com/iz2a86l.png" />
</p>

H√†m m·∫•t m√°t theo paper (Vinyals et al. 2014) [Show and Tell: A Neural Image Caption Generator](https://arxiv.org/search/cs?searchtype=author&query=Vinyals%2C+O)
### L∆∞u √Ω: M·∫•t m√°t trong phi√™n b·∫£n attention
V·ªõi attention, th√™m m·ªôt th√†nh ph·∫ßn v√†o loss: double stochastic regularization.
<p align="center">
  <img src="https://i.imgur.com/mNbrTo5.png" />
</p>
ƒêi·ªÅu n√†y khuy·∫øn kh√≠ch model ch√∫ √Ω ƒë·ªÅu ƒë·∫øn m·ªçi ph·∫ßn c·ªßa ·∫£nh trong qu√° tr√¨nh sinh caption.

## Th√≠ nghi·ªám c√° nh√¢n
D∆∞·ªõi ƒë√¢y l√† c√°c l·∫ßn hu·∫•n luy·ªán t√¥i ƒë√£ th·ª±c hi·ªán, c√°c model pretrained n·∫±m trong th∆∞ m·ª•c `.saved`
![Training Table](https://i.imgur.com/sqgEPzM.png)

# T√†i li·ªáu tham kh·∫£o

 -  (Vinyals et al. 2014) [Show and Tell: A Neural Image Caption Generator](https://arxiv.org/abs/1411.4555) 
 - (Xu et al. 2015) [Show, Attend and Tell: Neural Image Caption Generation with Visual Attention](https://arxiv.org/pdf/1502.03044.pdf)
 - T√†i li·ªáu, m√£ ngu·ªìn v√† b√†i gi·∫£ng c·ªßa Gi√°o s∆∞ [Stefano Melacci](https://www3.diism.unisi.it/~melacci/)

## üìë T√≥m t·∫Øt file eval_app.py

`eval_app.py` l√† ·ª©ng d·ª•ng web s·ª≠ d·ª•ng Streamlit ƒë·ªÉ ƒë√°nh gi√° m√¥ h√¨nh sinh ch√∫ th√≠ch ·∫£nh ti·∫øng Vi·ªát v·ªõi c√°c m√¥ h√¨nh CaRNet. ·ª®ng d·ª•ng h·ªó tr·ª£ hai ch·∫ø ƒë·ªô:
- **·∫¢nh ƒë∆°n**: Cho ph√©p ng∆∞·ªùi d√πng t·∫£i l√™n m·ªôt ·∫£nh, sinh caption v√† hi·ªÉn th·ªã k·∫øt qu·∫£ tr·ª±c ti·∫øp.
- **To√†n b·ªô th∆∞ m·ª•c**: ƒê√°nh gi√° t·ª± ƒë·ªông t·∫•t c·∫£ ·∫£nh trong m·ªôt th∆∞ m·ª•c, xu·∫•t k·∫øt qu·∫£ ra file CSV.

C√°c t√≠nh nƒÉng ch√≠nh:
- Ch·ªçn m√¥ h√¨nh CaRNet (vI, vH, vHC, vHCAttention) v√† giao di·ªán s√°ng/t·ªëi.
- T√πy ch·ªçn ch·∫ø ƒë·ªô ƒë√°nh gi√° (·∫£nh ƒë∆°n ho·∫∑c th∆∞ m·ª•c).
- Hi·ªÉn th·ªã logo, ti√™u ƒë·ªÅ, m√¥ t·∫£ ·ª©ng d·ª•ng.
- T·ª± ƒë·ªông t·∫£i v√† c·∫•u h√¨nh m√¥ h√¨nh ph√π h·ª£p.
- T√≠nh ƒëi·ªÉm BLEU cho caption.
- L∆∞u k·∫øt qu·∫£ ƒë√°nh gi√° h√†ng lo·∫°t v√†o file `eval_results.csv`.

·ª®ng d·ª•ng gi√∫p ki·ªÉm th·ª≠, tr√¨nh di·ªÖn v√† ƒë√°nh gi√° nhanh hi·ªáu qu·∫£ c√°c m√¥ h√¨nh sinh ch√∫ th√≠ch ·∫£nh trong d·ª± √°n.

## T√°c gi·∫£

- [@Thisorp](https://www.github.com/Thisorp)
=======
üí° **L∆∞u √Ω th√™m:**
- `--attention t` d√πng ƒë·ªÉ b·∫≠t ch·∫ø ƒë·ªô attention cho m√¥ h√¨nh `CaRNetvHCAttention`.
- `--attention_dim` n√™n ƒë·ªÉ 1024 (m·∫∑c ƒë·ªãnh khuy·∫øn ngh·ªã).
- N·∫øu kh√¥ng cung c·∫•p `--image_path`, ch∆∞∆°ng tr√¨nh s·∫Ω duy·ªát to√†n b·ªô th∆∞ m·ª•c `images/`.

